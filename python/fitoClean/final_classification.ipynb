{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOtWGBVrOXxh"
      },
      "outputs": [],
      "source": [
        "!pip install pyheif\n",
        "\n",
        "from PIL import Image\n",
        "import pyheif\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "import PIL.Image as Image\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import display, clear_output\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from matplotlib import rc\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "rcParams['figure.figsize'] = 16, 10\n",
        "\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='ПУТЬ К ВЕСАМ')\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def seed_all(seed_value):\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_all(0)"
      ],
      "metadata": {
        "id": "LMYzV2lpJCku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь изображения загружаются и кладутся в массивы class_0_imgs, class_1_imgs, class_2_imgs в виде объектов PiL.Image, соответствующие здоровым растениям, больным бурой ржавчиной и белой гнилью соответственно. Ячейка скрыта ввиду ограничений на распространение данных."
      ],
      "metadata": {
        "id": "3eqLRLSn52Ib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import models, transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "msRVELdZMjN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "sxLTQdsYLIYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# сохранение локально фотографий в формате .jpg по 3м разным директориям, пути к файлам нужны дальше для подачи в модель model(path)\n",
        "\n",
        "os.mkdir('class0')\n",
        "os.mkdir('class1')\n",
        "os.mkdir('class2')"
      ],
      "metadata": {
        "id": "H2gxqh9tMgpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, image in enumerate(class_0_imgs):\n",
        "    image.save('class0/' + str(i) + '.jpg')\n",
        "for i, image in enumerate(class_1_imgs):\n",
        "    image.save('class1/' + str(i) + '.jpg')\n",
        "for i, image in enumerate(class_2_imgs):\n",
        "    image.save('class2/' + str(i) + '.jpg')"
      ],
      "metadata": {
        "id": "tUIWa6KoTLAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# вычисление предсказаний нахождения симптомов того или иного заболевания\n",
        "# preds_all[i][j][k] соответствует k-ой предсказанной рамке для j-ой фотографии i-ого класса\n",
        "# предсказанная рамка - массив [x1, y1, x2, y2, conf, class]\n",
        "\n",
        "preds_all = [[], [], []]\n",
        "dirs = ['class0', 'class1', 'class2']\n",
        "imgs_lens = [len(class_0_imgs), len(class_1_imgs), len(class_2_imgs)]\n",
        "for j, dir in enumerate(dirs):\n",
        "    inds = np.arange(imgs_lens[j])\n",
        "    inds1 = inds[ : len(inds) // 100 * 100].reshape((-1, 100))\n",
        "    inds2 = inds[len(inds) // 100 * 100:]\n",
        "    for k in range(inds1.shape[0]):\n",
        "        imgs = [dir + '/' + str(num) + '.jpg' for num in inds1[k]]\n",
        "        preds = model(imgs).pred\n",
        "        for i in range(len(preds)):\n",
        "            preds[i] = preds[i].cpu()\n",
        "        preds_all[j] += preds\n",
        "    imgs = [dir + '/' + str(num) + '.jpg' for num in inds2]\n",
        "    preds = model(imgs).pred\n",
        "    for i in range(len(preds)):\n",
        "        preds[i] = preds[i].cpu()\n",
        "    preds_all[j] += preds"
      ],
      "metadata": {
        "id": "G495R1LqJpjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YG_XA6A0t_v4"
      },
      "outputs": [],
      "source": [
        "# собираем все предсказания в один массив\n",
        "\n",
        "X = []\n",
        "for preds_per_class in preds_all:\n",
        "    X += preds_per_class\n",
        "y = np.array([0] * len(class_0_imgs) + [1] * len(class_1_imgs) + [2] * len(class_2_imgs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwJ45LzYTe3T"
      },
      "outputs": [],
      "source": [
        "# делим на трейн / тест, как при обучении\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxXoUCN5t6mv"
      },
      "outputs": [],
      "source": [
        "# max_len - количество учитываемых предсказанных рамок для одной фотографии (самых вероятных)\n",
        "# убираем координаты рамок, дополняем недостающие предсказания 0\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y, max_len):\n",
        "        self.x = x\n",
        "        lens = []\n",
        "        for i in range(len(self.x)):\n",
        "            if self.x[i].shape[0]:\n",
        "                self.x[i] = self.x[i][:, 4:]\n",
        "            else:\n",
        "                self.x[i].reshape((0, 2))\n",
        "            conf = self.x[i][:, 0]\n",
        "            argsort = torch.argsort(conf, dim=0, descending=True)\n",
        "            self.x[i] = self.x[i].flatten()[: max_len * 2].tolist()\n",
        "            self.x[i] += [0.] * (max_len * 2 - len(self.x[i])) + [len(self.x[i])]\n",
        "            \n",
        "        self.y = y.reshape((y.shape[0], 1))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.x[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.float32)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDohOuw1d0Up"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 200\n",
        "\n",
        "max_len = 50\n",
        "\n",
        "train_dataset = MyDataset(X_train, y_train, max_len)\n",
        "test_dataset = MyDataset(X_test, y_test, max_len)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Sequential(\n",
        "           nn.Linear(max_len * 2 + 1, 200),\n",
        "           nn.ReLU(),\n",
        "           nn.Linear(200, 150),\n",
        "           nn.ReLU(),\n",
        "           nn.Linear(150, 3),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "vk0bRicQ-qwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbPSbj5td0YY"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model = torch.load('model_params.pt', map_location=device) # model_params - обученные веса модели 2\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor([y.shape[0] / (y==0).sum(), y.shape[0] / (y==1).sum(), y.shape[0] / (y==2).sum()], dtype=torch.float).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taajVKXUO3xk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "030c18dc-4cb6-4073-d6db-0f112350f8be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 19.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy =  tensor(0.93328)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14/14 [00:00<00:00, 43.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train accuracy =  tensor(0.94351)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import display\n",
        "from time import time\n",
        "\n",
        "num_matches = 0\n",
        "model.eval()\n",
        "for x, y in tqdm(test_dataloader):\n",
        "    with torch.no_grad():\n",
        "            \n",
        "        x = x.to(device)\n",
        "        y = y.type(torch.LongTensor).squeeze(1)\n",
        "        logits = model(x).cpu()\n",
        "        num_matches += (np.argmax(logits, 1) == y).sum()\n",
        "        \n",
        "        \n",
        "print('test accuracy = ', num_matches / len(test_dataset))\n",
        "\n",
        "num_matches = 0\n",
        "model.eval()\n",
        "for x, y in tqdm(train_dataloader):\n",
        "    with torch.no_grad():\n",
        "            \n",
        "        x = x.to(device)\n",
        "        y = y.type(torch.LongTensor).squeeze(1)\n",
        "        logits = model(x).cpu()\n",
        "        num_matches += (np.argmax(logits, 1) == y).sum()\n",
        "print('')\n",
        "print('train accuracy = ', num_matches / len(train_dataset))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Копия блокнота \"only_heic_classification.ipynb\"",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}